I"<p>在小菜初学<code class="language-plaintext highlighter-rouge">scrapy</code>时，从google上发现了几篇非常不错的文章，未经博主同意擅自将博主的文章收藏，主要怕日后看时，找不到此文章。小菜在这里向博主致敬，希望看到这篇帖子的小伙伴能够阅读原贴。</p>

<ul>
  <li><a href="http://kaito-kidd.com/2016/11/01/scrapy-code-analyze-architecture/" title="http://kaito-kidd.com/2016/11/01/scrapy-code-analyze-architecture/">Kaito 博主</a></li>
</ul>

<p>在爬虫领域，使用最多的主流语言主要是Java和Python这两种，而开源爬虫框架Scrapy正是由Python编写的。</p>

<p>Scrapy在开源爬虫框架中名声很大，几乎用Python写爬虫的人，都用过这个框架。市场上很多爬虫框架都是模仿和参考Scrapy的思想和架构实现的，如果想深入学习爬虫，研读Scrapy的源码还是很有必要的。</p>

<p>这个系列的文章主要记录自己当时做爬虫时，读源码的思路和经验整理，本篇先从宏观角度介绍整个Scrapy的架构和运行流程。</p>

<h1 id="1介绍">1.介绍</h1>

<p><strong>Scrapy是一个基于Python编写的一个开源爬虫框架，它可以帮你快速、简单的方式构建爬虫，并从网站上提取你所需要的数据。</strong></p>

<p>也就是说，使用Scrapy能帮你快速简单的编写一个爬虫，用来抓取网站数据</p>

<p>这里不再介绍Scrapy的安装和使用，本系列主要通过阅读源码讲解Scrapy实现思路为主。如果有不懂如何使用的同学，请参考官方网站或官方文档学习。（写本篇文章时，Scrapy版本为1.2）</p>

<p>因为使用比较简单，使用Scrapy官网上的例子来说明如何构建爬虫：</p>

<p><img src="http://walidream.com:9999/blogImage/python/python_23.png" alt="ssl" /></p>

<p>简单来说构建和运行一个爬虫只需完成以下几步：</p>
<ul>
  <li>使用<code class="language-plaintext highlighter-rouge">scrapy startproject</code>创建爬虫模板或自己编写爬虫脚本</li>
  <li>爬虫类继承<code class="language-plaintext highlighter-rouge">scrapy.Spider</code>，重写<code class="language-plaintext highlighter-rouge">parse</code>方法</li>
  <li><code class="language-plaintext highlighter-rouge">parse</code>方法中<code class="language-plaintext highlighter-rouge">yield</code>或<code class="language-plaintext highlighter-rouge">return</code>字典、<code class="language-plaintext highlighter-rouge">Request</code>、<code class="language-plaintext highlighter-rouge">Item</code></li>
  <li>使用<code class="language-plaintext highlighter-rouge">scrapy crawl &lt;spider_name</code>&gt;或<code class="language-plaintext highlighter-rouge">scrapy runspider &lt;spider_file.py&gt;</code>运行</li>
</ul>

<p>经过简单的几行代码，就能采集到某个网站下一些页面的数据，非常方便。但是在这背后到底发生了什么？Scrapy到底是如何帮助我们工作的呢？</p>

<h1 id="2架构">2.架构</h1>

<p><img src="http://walidream.com:9999/blogImage/python/python_22.png" alt="ssl" /></p>

<h1 id="3核心组件">3.核心组件</h1>

<p>Scrapy有以下几大组件：</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Scrapy Engine</code>：核心引擎，负责控制和调度各个组件，保证数据流转</li>
  <li><code class="language-plaintext highlighter-rouge">Scheduler</code>：负责管理任务、过滤任务、输出任务的调度器，存储、去重任务都在此控制</li>
  <li><code class="language-plaintext highlighter-rouge">Downloader</code>：下载器，负责在网络上下载网页数据，输入待下载URL，输出下载结果</li>
  <li><code class="language-plaintext highlighter-rouge">Spiders</code>：用户自己编写的爬虫脚本，可自定义抓取意图</li>
  <li><code class="language-plaintext highlighter-rouge">Item Pipeline</code>：负责输出结构化数据，可自定义输出位置</li>
  <li><code class="language-plaintext highlighter-rouge">Downloader middlewares</code>：介于引擎和下载器之间，可以在网页在下载前、后进行逻辑处理</li>
  <li><code class="language-plaintext highlighter-rouge">Spider middlewares</code>：介于引擎和爬虫之间，可以在调用爬虫输入下载结果和输出请求/数据时进行逻辑处理</li>
</ul>

<h1 id="4数据流转">4.数据流转</h1>

<p>按照架构图的序号，数据流转大概是这样的：</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">引擎</code>从<code class="language-plaintext highlighter-rouge">自定义爬虫</code>中获取初始化请求（也叫种子URL）</li>
  <li>擎把该请求放入<code class="language-plaintext highlighter-rouge">调度器中</code>，同时<code class="language-plaintext highlighter-rouge">引擎向调度器</code>获取一个<code class="language-plaintext highlighter-rouge">待下载的请求</code>（这两部是异步执行的）</li>
  <li>调度器返回给引擎一个<code class="language-plaintext highlighter-rouge">待下载</code>的请求</li>
  <li>引擎发送请求给<code class="language-plaintext highlighter-rouge">下载器</code>，中间会经过一系列<code class="language-plaintext highlighter-rouge">下载器中间件</code></li>
  <li>这个请求通过下载器下载完成后，生成一个<code class="language-plaintext highlighter-rouge">响应对象</code>，返回给引擎，这中间会再次经过一系列<code class="language-plaintext highlighter-rouge">下载器中间件</code></li>
  <li>引擎接收到下载返回的响应对象后，然后发送给爬虫，执行<code class="language-plaintext highlighter-rouge">自定义爬虫逻辑</code>，中间会经过一系列<code class="language-plaintext highlighter-rouge">爬虫中间件</code></li>
  <li>爬虫执行对应的回调方法，处理这个响应，完成用户逻辑后，会生成<code class="language-plaintext highlighter-rouge">结果对象</code>或<code class="language-plaintext highlighter-rouge">新的请求对象</code>给引擎，再次经过一系列<code class="language-plaintext highlighter-rouge">爬虫中间件</code></li>
  <li>引擎把爬虫返回的结果对象交由<code class="language-plaintext highlighter-rouge">结果处理器</code>处理，把<code class="language-plaintext highlighter-rouge">新的请求</code>对象通过引擎再交给调度器</li>
  <li>从1开始重复执行，直到调度器中没有新的请求处理</li>
</ol>

<h1 id="5核心组件交互图">5.核心组件交互图</h1>

<p>我在读完源码后，整理出一个更详细的架构图，其中展示了更多相关组件的细节:</p>

<p><img src="http://walidream.com:9999/blogImage/python/python_24.png" alt="ssl" /></p>

<p>这里需要说明一下图中的<code class="language-plaintext highlighter-rouge">Scrapyer</code>，其实这也是在源码的一个核心类，但官方架构图中没有展示出来，这个类其实是处于<code class="language-plaintext highlighter-rouge">Engine</code>、<code class="language-plaintext highlighter-rouge">Spiders</code>、<code class="language-plaintext highlighter-rouge">Pipeline</code>之间，是连通这3个组件的桥梁，后面在文章中会具体讲解。</p>

<h1 id="6核心类图">6.核心类图</h1>

<p>涉及到的一些核心类如下：</p>

<p><img src="http://walidream.com:9999/blogImage/python/python_25.png" alt="ssl" /></p>

<p>其中标没有样式的<code class="language-plaintext highlighter-rouge">黑色文字</code>是类的核心<code class="language-plaintext highlighter-rouge">属性</code>，<code class="language-plaintext highlighter-rouge">黄色样式</code>的文字都是<code class="language-plaintext highlighter-rouge">核心方法</code>。</p>

<p>可以看到，Scrapy的核心类，其实主要包含5大组件、4大中间件管理器、爬虫类和爬虫管理器、请求、响应对象和数据解析类这几大块。</p>

<p>大家先对整个架构有个认识，接下来的文章，会针对上述的这些类和方法进行源码讲解。</p>

:ET