I"!#<p>实现爬虫时最经常提到的需求就是能合适的保存爬取到的数据，或者说，生成一个带有爬取数据的<code class="language-plaintext highlighter-rouge">导出文件</code>(通常叫做<code class="language-plaintext highlighter-rouge">export feed</code>)，来供其他系统使用。</p>

<p>Scrapy 自带了 <code class="language-plaintext highlighter-rouge">Feed</code> 输出，并且支持多种序列化格式(<code class="language-plaintext highlighter-rouge">serialization format</code>)及存储方式(<code class="language-plaintext highlighter-rouge">storage backends</code>)</p>

<h1 id="1序列化方式">1.序列化方式</h1>

<h4 id="serialization-formats">Serialization formats</h4>

<p><code class="language-plaintext highlighter-rouge">feed</code>输出使用到了 <code class="language-plaintext highlighter-rouge">Item exporters</code>。其自带支持的类型有:</p>
<ul>
  <li>JSON</li>
  <li>JSON lines</li>
  <li>CSV</li>
  <li>XML</li>
</ul>

<p>您也可以通过 <code class="language-plaintext highlighter-rouge">FEED_EXPORTERS</code> 设置扩展支持的属性。</p>

<h4 id="json">JSON</h4>

<p>JSON:</p>
<ul>
  <li>FEED_FORMAT: json</li>
  <li>使用的 exporter: JsonItemExporter</li>
  <li>大数据量情况下使用 JSON 请参见 这个警告</li>
</ul>

<h4 id="json-lines">JSON lines</h4>

<p>JSON lines:</p>
<ul>
  <li>FEED_FORMAT: jsonlines</li>
  <li>使用的 exporter: JsonLinesItemExporter</li>
</ul>

<h4 id="csv">CSV</h4>

<p>CSV:</p>
<ul>
  <li>FEED_FORMAT: csv</li>
  <li>使用的 exporter: CsvItemExporter</li>
</ul>

<h4 id="xml">XML</h4>

<p>XML:</p>
<ul>
  <li>FEED_FORMAT: xml</li>
  <li>使用的exporter: XmlItemExporter</li>
</ul>

<h4 id="pickle">Pickle</h4>

<p>Pickle:</p>
<ul>
  <li>FEED_FORMAT: pickle</li>
  <li>使用的 exporter: PickleItemExporter</li>
</ul>

<h4 id="marshal">Marshal</h4>

<p>Marshal:</p>
<ul>
  <li>FEED_FORMAT: marshal</li>
  <li>使用的exporter: MarshalItemExporter</li>
</ul>

<h1 id="2存储">2.存储</h1>

<p>使用 feed 输出时您可以通过使用 URI(通过 <code class="language-plaintext highlighter-rouge">FEED_URI</code> 设置) 来定义存储端。feed 输出支持 URI 方式支持的多种存储后端类型。</p>

<p>自带支持的存储后端有:</p>
<ul>
  <li>本地文件系统</li>
  <li>FTP</li>
  <li>S3 (需要 boto)</li>
  <li>标准输出</li>
</ul>

<p>有些存储后端会因所需的外部库未安装而不可用。例如，S3只有在<code class="language-plaintext highlighter-rouge">boto</code>库安装的情况下才可使用。</p>

<h1 id="3存储uri参数">3.存储URI参数</h1>

<p>存储 <code class="language-plaintext highlighter-rouge">URI</code> 也包含参数。当<code class="language-plaintext highlighter-rouge">feed</code>被创建时这些参数可以被覆盖</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">%(time)s</code> - 当 feed 被创建时被 timestamp 覆盖</li>
  <li><code class="language-plaintext highlighter-rouge">%(name)s</code> - 被 spider 的名字覆盖</li>
</ul>

<p>其他命名的参数会被 <code class="language-plaintext highlighter-rouge">spider</code>同名的属性所覆盖。例如， 当 feed 被创建时， <code class="language-plaintext highlighter-rouge">%(site_id)s </code>将会被 <code class="language-plaintext highlighter-rouge">spider.site_id</code> 属性所覆盖。</p>

<p>下面用一些例子来说明:</p>

<p>1.存储在<code class="language-plaintext highlighter-rouge">FTP</code>，每个 <code class="language-plaintext highlighter-rouge">spider</code>一个目录:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ftp://user:password@ftp.example.com/scraping/feeds/%(name)s/%(time)s.json
</code></pre></div></div>

<p>2.存储在<code class="language-plaintext highlighter-rouge">S3</code>，每一个spider一个目录:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>s3://mybucket/scraping/feeds/%(name)s/%(time)s.json
</code></pre></div></div>

<h1 id="4本地文件系统">4.本地文件系统</h1>

<p>将 feed 存储在本地系统:</p>
<ul>
  <li>URI scheme: <code class="language-plaintext highlighter-rouge">file</code></li>
  <li>URI 样例: <code class="language-plaintext highlighter-rouge">file:///tmp/export.csv</code></li>
  <li>需要的外部依赖库:<code class="language-plaintext highlighter-rouge">none</code></li>
</ul>

<p><code class="language-plaintext highlighter-rouge">注意</code>: (只有)存储在本地文件系统时，您可以指定一个绝对路径 <code class="language-plaintext highlighter-rouge">tmp/export.csv</code> 并忽略协议(scheme)。不过这仅仅只能在 Unix 系统中工作。</p>

<h4 id="ftp">FTP</h4>

<p>将feed存储在FTP服务器</p>
<ul>
  <li>URI scheme:<code class="language-plaintext highlighter-rouge">ftp</code></li>
  <li>URI 样例:<code class="language-plaintext highlighter-rouge">ftp://user:pass@ftp.example.com/path/to/export.csv</code></li>
  <li>需要的外部依赖库:<code class="language-plaintext highlighter-rouge">none</code></li>
</ul>

<h4 id="s3">S3</h4>

<p>将feed存储在 Amazon S3</p>
<ul>
  <li>URI scheme: <code class="language-plaintext highlighter-rouge">s3</code></li>
  <li>URI 样例:</li>
  <li>s3://mybucket/path/to/export.csv</li>
  <li>s3://mybucket/path/to/export.csv</li>
  <li>需要的外部依赖库: <code class="language-plaintext highlighter-rouge">boto</code></li>
</ul>

<p>您可以通过在 <code class="language-plaintext highlighter-rouge">URI</code> 中传递 <code class="language-plaintext highlighter-rouge">user/pass</code> 来完成 AWS 认证，或者也可以通过下列的设置来完成:</p>

<p><code class="language-plaintext highlighter-rouge">AWS_ACCESS_KEY_ID</code> <code class="language-plaintext highlighter-rouge">AWS_SECRET_ACCESS_KEY</code></p>

<h4 id="标准输出">标准输出</h4>

<p>feed 输出到 <code class="language-plaintext highlighter-rouge">Scrapy</code>进程的标准输出</p>
<ul>
  <li>URI scheme: <code class="language-plaintext highlighter-rouge">stdout</code></li>
  <li>URI 样例: <code class="language-plaintext highlighter-rouge">stdout:</code></li>
  <li>需要的外部依赖库: none</li>
</ul>

<h1 id="5settings">5.Settings</h1>

<p>这些是配置 feed 输出的设定:</p>
<ul>
  <li>FEED_URI (必须)</li>
  <li>FEED_FORMAT</li>
  <li>FEED_STORAGES</li>
  <li>FEED_STORAGE_FTP_ACTIVE</li>
  <li>FEED_STORAGE_S3_ACL</li>
  <li>FEED_EXPORTERS</li>
  <li>FEED_STORE_EMPTY</li>
  <li>FEED_EXPORT_ENCODING</li>
  <li>FEED_EXPORT_FIELDS</li>
  <li>FEED_EXPORT_INDENT</li>
</ul>

<table>
  <thead>
    <tr>
      <th>设置</th>
      <th>默认值</th>
      <th>描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>FEED_URI</td>
      <td>None</td>
      <td>输出 feed 的 URI</td>
    </tr>
    <tr>
      <td>FEED_FORMAT</td>
      <td> </td>
      <td>输出 feed 的序列化格式</td>
    </tr>
    <tr>
      <td>FEED_EXPORT_ENCODING</td>
      <td>None</td>
      <td>使用feed编码</td>
    </tr>
    <tr>
      <td>FEED_EXPORT_FIELDS</td>
      <td>None</td>
      <td>使用FEED_EXPORT_FIELDS选项定义要导出的字段及其顺序</td>
    </tr>
    <tr>
      <td>FEED_EXPORT_INDENT</td>
      <td>0</td>
      <td> </td>
    </tr>
    <tr>
      <td>FEED_STORE_EMPTY</td>
      <td>False</td>
      <td>是否导出空的feeds（即没有item)</td>
    </tr>
    <tr>
      <td>FEED_STORAGES</td>
      <td>{}</td>
      <td>包含您的项目支持的其他提要存储后端的字典。密钥是URI方案，值是存储类的路径。</td>
    </tr>
    <tr>
      <td>FEED_STORAGE_FTP_ACTIVE</td>
      <td>False</td>
      <td> </td>
    </tr>
    <tr>
      <td>FEED_STORAGE_S3_ACL</td>
      <td>’’</td>
      <td> </td>
    </tr>
    <tr>
      <td>FEED_STORAGES_BASE</td>
      <td>{<br />’’: ‘scrapy.extensions.feedexport.FileFeedStorage’,<br />‘file’: ‘scrapy.extensions.feedexport.FileFeedStorage’,<br />‘stdout’: ‘scrapy.extensions.feedexport.StdoutFeedStorage’,<br />‘s3’: ‘scrapy.extensions.feedexport.S3FeedStorage’,<br /> ‘ftp’: ‘scrapy.extensions.feedexport.FTPFeedStorage’,<br />}</td>
      <td> </td>
    </tr>
    <tr>
      <td>FEED_EXPORTERS</td>
      <td>{}</td>
      <td> </td>
    </tr>
    <tr>
      <td>FEED_EXPORTERS_BASE</td>
      <td>{<br />‘json’: ‘scrapy.exporters.JsonItemExporter’,<br />‘jsonlines’: ‘scrapy.exporters.JsonLinesItemExporter’,<br /> ‘jl’: ‘scrapy.exporters.JsonLinesItemExporter’,<br />‘csv’: ‘scrapy.exporters.CsvItemExporter’,<br />‘xml’: ‘scrapy.exporters.XmlItemExporter’,<br /> ‘marshal’: ‘scrapy.exporters.MarshalItemExporter’,<br /> ‘pickle’: ‘scrapy.exporters.PickleItemExporter’,<br />}</td>
      <td> </td>
    </tr>
  </tbody>
</table>

:ET