I"!&<p>Scrapy是通过<code class="language-plaintext highlighter-rouge">scrapy</code> 命令行工具进行控制的。 这里我们称之为 <code class="language-plaintext highlighter-rouge">Scrapy tool</code>以用来和子命令进行区分。 对于子命令，我们称为 “command” 或者 “Scrapy commands”。</p>

<h1 id="1配置设置">1.配置设置</h1>

<p>Scrapy将会在以下路径中寻找记录了配置参数的 scrapy.cfg 文件, 该文件以ini的方式记录:</p>

<ul>
  <li>1.<code class="language-plaintext highlighter-rouge">/etc/scrapy.cfg</code> 或 <code class="language-plaintext highlighter-rouge">c:\scrapy\scrapy.cfg</code> (系统层面)</li>
  <li>2.<code class="language-plaintext highlighter-rouge">~/.config/scrapy.cfg ($XDG_CONFIG_HOME)</code> 及<code class="language-plaintext highlighter-rouge">~/.scrapy.cfg ($HOME)</code> 作为全局(用户层面)设置</li>
  <li>3.在scrapy项目根路径下的 <code class="language-plaintext highlighter-rouge">scrapy.cfg</code></li>
</ul>

<p>从这些文件中读取到的设置按照以下顺序合并：项目中<code class="language-plaintext highlighter-rouge">scrapy.cfg</code> &gt; <code class="language-plaintext highlighter-rouge">~/.scrapy.cfg</code> &gt; <code class="language-plaintext highlighter-rouge">/etc/scrapy.cfg</code></p>

<h1 id="2默认的scrapy项目结构">2.默认的scrapy项目结构</h1>

<pre><code class="language-txt">/
|--scrapy.cfg
|--myproject/
     |--__init__.py
     |--items.py
     |--pipelines.py
     |--settings.py
     |--spiders/
         |--__init__.py
         |--spider1.py
         |--spider2.py
</code></pre>

<p><code class="language-plaintext highlighter-rouge">scrapy.cfg 存放的目录被认为是 项目的根目录</code> 。该文件中包含python模块名的字段定义了项目的设置。例如:</p>

<pre><code class="language-txt">[settings]
default = myproject.settings
</code></pre>

<h1 id="3工具命令">3.工具命令</h1>

<p><code class="language-plaintext highlighter-rouge">scrapy</code>提供了可用的内置命令的列表。您可用通过运行命令来获取每个命令的详细内容。</p>

<pre><code class="language-txt"># 单个命令详情
scrapy &lt;command&gt; -h

#查看所有可用的命令
scrapy -h
</code></pre>

<p>Scrapy提供了两种类型的命令。一种必须在Scrapy项目中运行(针对项目(<code class="language-plaintext highlighter-rouge">Project-specific</code>)的命令)，另外一种则不需要(<code class="language-plaintext highlighter-rouge">全局命令</code>)。全局命令在项目中运行时的表现可能会与在非项目中运行有些许差别(因为可能会使用项目的设定)。</p>

<h4 id="全局命令">全局命令</h4>

<table>
  <thead>
    <tr>
      <th>命令</th>
      <th>描述</th>
      <th>语法</th>
      <th>是否需要项目</th>
      <th>例子</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>startproject</td>
      <td>在文件夹下创建一个名为<code class="language-plaintext highlighter-rouge">project_name</code>的scrapy项目</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy startproject &lt;project_name&gt;</code></td>
      <td>否</td>
      <td>scrapy startproject myproject</td>
    </tr>
    <tr>
      <td>settings</td>
      <td>在项目中运行时，该命令将会输出项目的设定值，否则输出Scrapy默认设定</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy settings [options]</code></td>
      <td>否</td>
      <td>scrapy settings –get BOT_NAME <br /> scrapybot <br /> scrapy settings –get DOWNLOAD_DELAY <br /> 0</td>
    </tr>
    <tr>
      <td>runspider</td>
      <td>在未创建项目的情况下，运行一个编写在Python文件中的spider</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy runspider &lt;spider_file.py&gt;</code></td>
      <td>否</td>
      <td>scrapy runspider myspider.py</td>
    </tr>
    <tr>
      <td>shell</td>
      <td>启动Scrapy终端</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy shell [url]</code></td>
      <td>否</td>
      <td>scrapy shell http://www.example.com/some/page.html</td>
    </tr>
    <tr>
      <td>fetch</td>
      <td>使用Scrapy下载器(downloader)下载给定的URL，并将获取到的内容送到标准输出</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy fetch &lt;url&gt;</code></td>
      <td>否</td>
      <td>scrapy fetch –nolog http://www.example.com/some/page.html</td>
    </tr>
    <tr>
      <td>view</td>
      <td>在浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现。 有些时候spider获取到的页面和普通用户看到的并不相同。 因此该命令可以用来检查spider所获取到的页面，并确认这是您所期望的</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy view &lt;url&gt;</code></td>
      <td>否</td>
      <td>scrapy view http://www.example.com/some/page.html</td>
    </tr>
    <tr>
      <td>version</td>
      <td>输出Scrapy版本。配合<code class="language-plaintext highlighter-rouge">-v</code>运行时,该命令同时输出Python,Twisted 以及平台的信息，方便bug提交</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy version [-v]</code></td>
      <td>否</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h4 id="项目project命令">项目(project)命令</h4>

<table>
  <thead>
    <tr>
      <th>命令</th>
      <th>描述</th>
      <th>语法</th>
      <th>是否需要项目</th>
      <th>例子</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>crawl</td>
      <td>使用spider进行爬取</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy crawl &lt;spider&gt;</code></td>
      <td>是</td>
      <td>scrapy crawl myspider</td>
    </tr>
    <tr>
      <td>check</td>
      <td>运行contract检查</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy check [-l] &lt;spider&gt;</code></td>
      <td>是</td>
      <td>scrapy check -l <br /> scrapy check</td>
    </tr>
    <tr>
      <td>list</td>
      <td>列出当前项目中所有可用的spider。每行输出一个spider</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy list</code></td>
      <td>是</td>
      <td>scrapy list</td>
    </tr>
    <tr>
      <td>edit</td>
      <td>使用 EDITOR 中设定的编辑器编辑给定的spider</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy edit &lt;spider&gt;</code></td>
      <td>是</td>
      <td>scrapy edit spider1</td>
    </tr>
    <tr>
      <td>parse</td>
      <td>获取给定的URL并使用相应的spider分析处理。如果您提供 <code class="language-plaintext highlighter-rouge">--callback</code> 选项，则使用spider的该方法处理，否则使用 <code class="language-plaintext highlighter-rouge">parse</code></td>
      <td><code class="language-plaintext highlighter-rouge">scrapy parse &lt;url&gt; [options]</code></td>
      <td>是</td>
      <td>scrapy parse http://www.example.com/ -c parse_item</td>
    </tr>
    <tr>
      <td>genspider</td>
      <td>在当前项目中创建spider</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;</code></td>
      <td>是</td>
      <td>scrapy genspider -l <br /> scrapy genspider -d basic</td>
    </tr>
    <tr>
      <td>bench</td>
      <td>运行benchmark测试</td>
      <td><code class="language-plaintext highlighter-rouge">scrapy bench</code></td>
      <td>是</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="parse选项">parse选项</h3>

<table>
  <thead>
    <tr>
      <th>选项</th>
      <th>描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--spider=SPIDER</code></td>
      <td>跳过自动检测spider并强制使用特定的spider</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--a NAME=VALUE</code></td>
      <td>设置spider的参数(可能被重复</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--callback</code> or <code class="language-plaintext highlighter-rouge">-c</code></td>
      <td>spider中用于解析返回(response)的回调函数</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--pipelines</code></td>
      <td>在pipeline中处理item</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--rules</code> or <code class="language-plaintext highlighter-rouge">-r</code></td>
      <td>使用 CrawlSpider 规则来发现用来解析返回(response)的回调函数</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--noitems</code></td>
      <td>不显示爬取到的item</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--nolinks</code></td>
      <td>不显示提取到的链接</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--nocolour</code></td>
      <td>避免使用pygments对输出着色</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--depth</code> or <code class="language-plaintext highlighter-rouge">-d</code></td>
      <td>指定跟进链接请求的层次数</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">--verbose</code> or <code class="language-plaintext highlighter-rouge">-v</code></td>
      <td>显示每个请求的详细信息</td>
    </tr>
  </tbody>
</table>

:ET