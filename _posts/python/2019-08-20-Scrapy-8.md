---
layout: post
title: Scrapy 架构概览(8) #标题
tagline: Feed exports
category: python      #分类
author: wali    #作者
tag: Scrapy     #标签
ghurl:        #github url
ghurl_zip:   #github zip下载
comments: true

post_nav: ["1.总览","2.组件"] 
group_tag: Scrapy 1.7
---

在学习了scrapy基础后，我们在来了解一下scrapy的架构概览，这有助于我们更好的了解、学习scrapy。下面介绍Scrapy的体系结构及其组件之间的交互方式。

# 1.总览

下图显示了Scrapy体系结构及其组件的概述，以及系统内部发生的数据流的概况（由红色箭头显示）。下面包括对这些组件的简要说明，以及有关它们的更多详细信息的链接。数据流也在下面描述。

![ssl]({{ site.url }}/assets/image/python/python_22.png)


Scrapy中的数据流由执行引擎控制，如下所示：
1. `engine`(引擎)从`spiders`(爬虫)获取初始请求
2. `engine`(引擎)在`scheduler`(调度器)调度请求，并请求下一个要爬取的请求
3. `scheduler`(调度器)返回`engine`(引擎)下一个要爬取的请求
4. `engine`(引擎)通过`middleware`(中间件)将请求发送到`downloader`(下载器)
5. 页面下载完成后`downloader`(下载器)会生成一个(带有该页面的)响应，并通过`downloader middlewares`(下载中间件)发送给`engine`(引擎)
6. `engine`(引擎)从`downloader`(下载器)接收响应，通过`spider middlewares`(爬虫中间件)将其发送到`spider`(爬虫)进行处理
7. `spider`(爬虫)处理响应后，再通过`spider middlewares`(爬虫中间件)返回抓取到`items`和新的请求到`engine`(引擎)
8. `engine`(引擎)将处理好的`items`发送到`Item pipelines`(item 管道)，然后发送已处理的请求到`scheduler`(调度器),并询问下个可能的请求
9. 重复该过程(从步骤1开始),直到`scheduler`(调度器)没有的请求。


# 2.组件

#### Scrapy Engine(引擎)

引擎负责控制数据流在系统中所有组件中流动，并在相应动作发生时触发事件。

#### Scheduler(调度器)

调度器从引擎接受请求并将其排队，以便之后引擎请求它们时提供给引擎。

#### Downloader(下载器)

下载器负责获取页面，并提供给引擎，引擎再将其提供给爬虫。


#### Spiders(爬虫)

Spider是Scrapy用户编写的用于解析请求并提取item或额外跟进的请求的类。

#### Item Pipeline

Item Pipeline负责处理爬虫提取出来的item。典型的任务有清理、 验证及持久化（例如存取到数据库中）。

#### Downloader middlewares(下载中间件)

下载器中间件是在引擎及下载器之间的特定钩子(specific hook)，当请求从引擎到下载器时处理请求，响应从下载器到引擎时处理响应。

如果要做以下的工作，就可以使用下载器中间件：
- 请求发送给下载器之前，处理这个请求（即，在Scrapy发送请求到网站之前）
- 传递响应到爬虫之前，修改收到的响应
- 发送一个新的请求到爬虫，而不是传递收到的响应到爬虫
- 没有获取网页，直接传递响应给爬虫
- 默默丢弃一些请求


#### Spider middlewares(爬虫中间件)

爬虫中间件是在引擎及爬虫之间的特定钩子(specific hook)，处理爬虫的输入（响应）和输出（items和请求）。

爬虫中间件的可以用来：
- 对爬虫调回的输出做后处理 —— 修改、添加、移除请求或items
- 后处理初始请求（start_requests）
- 处理爬虫异常
- 调用errback，而不是基于响应内容调回一些请求

#### Event-driven networking(事件驱动网络)

Scrapy是基于事件驱动网络框架 Twisted 编写的。因此，Scrapy基于并发考虑由非阻塞（异步）代码实现。











